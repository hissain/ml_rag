{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82fd1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install streamlit\n",
    "#!pip install streamlit-jupyter\n",
    "#!pip install PyPDF2\n",
    "#!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73f63a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a443ceb9e1434db48976b96b1eb549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Partitioning text:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8924ee62784782a8f7b84f09133067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding partitions:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import faiss\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "import docx\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "#from ollama import Ollama\n",
    "\n",
    "ollama_url_inf = \"http://localhost:11434/api/show\"\n",
    "ollama_url_emb = \"http://localhost:11434/api/embeddings\"\n",
    "ollama_url_gen = \"http://localhost:11434/api/generate\"\n",
    "ollama_model_name = \"llama3.2:latest\"\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def read_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "def read_excel(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    return df.to_string()\n",
    "\n",
    "def read_text(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def read_file(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        return read_pdf(file_path)\n",
    "    elif file_path.endswith('.docx'):\n",
    "        return read_docx(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        return read_excel(file_path)\n",
    "    elif file_path.endswith('.txt'):\n",
    "        return read_text(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "def partition_text(text, max_length):\n",
    "    sentences = text.split('. ')\n",
    "    partitions = []\n",
    "    current_part = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for sentence in tqdm(sentences, desc=\"Partitioning text\"):\n",
    "        current_length += len(sentence.split())\n",
    "        current_part.append(sentence)\n",
    "        \n",
    "        if current_length > max_length:\n",
    "            partitions.append('. '.join(current_part))\n",
    "            current_part = []\n",
    "            current_length = 0\n",
    "\n",
    "    if current_part:\n",
    "        partitions.append('. '.join(current_part))\n",
    "\n",
    "    return partitions\n",
    "\n",
    "def get_embedding_shape():\n",
    "    payload = { \"model\": ollama_model_name }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(ollama_url_inf, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if 'model_info' in result and 'llama.embedding_length' in result['model_info']:\n",
    "            embedding_length = result['model_info'][\"llama.embedding_length\"]\n",
    "            return embedding_length\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_embedding(text):\n",
    "    payload = { \"model\": ollama_model_name, \"prompt\": text}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(ollama_url_emb, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        embedding = np.array(result['embedding'])\n",
    "        return embedding\n",
    "    else:\n",
    "        return np.zeros(768)  # (adjust dimension based on model)\n",
    "\n",
    "def store_in_faiss(partitions):\n",
    "    dimension = get_embedding_shape()\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    doc_vectors = []\n",
    "    doc_ids = []\n",
    "    \n",
    "    for i, partition in tqdm(enumerate(partitions), total=len(partitions), desc=\"Embedding partitions\"):\n",
    "        embedding = get_embedding(partition)\n",
    "        index.add(np.array([embedding]))\n",
    "        doc_vectors.append(embedding)\n",
    "        doc_ids.append(i)\n",
    "    \n",
    "    return index, doc_ids\n",
    "\n",
    "def retrieve_with_rag(query, faiss_index, doc_ids, k=2):\n",
    "    query_embedding = get_embedding(query)\n",
    "    distances, indices = faiss_index.search(np.array([query_embedding]), k=k)\n",
    "    retrieved_docs = []\n",
    "    for i in tqdm(indices[0], desc=\"Retrieving documents\"):\n",
    "        if i >= len(partitions):\n",
    "            continue\n",
    "        doc_id = doc_ids[i]\n",
    "        retrieved_docs.append(partitions[doc_id])\n",
    "    combined_docs = \"\\n\".join(retrieved_docs)\n",
    "    rag_prompt = f\"Context:\\n{combined_docs}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "    payload = {\"model\": ollama_model_name, \"prompt\": rag_prompt, \"stream\": False}\n",
    "    response = requests.post(ollama_url_gen, headers={\"Content-Type\": \"application/json\"}, \n",
    "                             data=json.dumps(payload))\n",
    "    return response.json()\n",
    "\n",
    "def ask(query):\n",
    "    rag_response = retrieve_with_rag(query, faiss_index, doc_ids)\n",
    "    return rag_response[\"response\"]\n",
    "\n",
    "file_path = \"./../data/designpattern.pdf\"\n",
    "text_data = read_file(file_path)\n",
    "partitions = partition_text(text_data, max_length=512)\n",
    "\n",
    "faiss_index, doc_ids = store_in_faiss(partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8f6c4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9063f23ac14ff2a9608f707a94bf61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving documents:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"The document appears to be a lecture or presentation on Object-Oriented Programming (OOP) concepts, specifically Singleton and Adapter patterns.\\n\\nHere's a brief summary of the topics covered:\\n\\n1. **Singleton pattern**: A design pattern that restricts a class from instantiating multiple objects.\\n2. **Reuse**: The Singleton pattern can be used to inherit functionality in subclasses, but it may not be easy to override the object instance in subclasses.\\n3. **Separation of Concerns**: Using a separate singleton class for creation and using it as a builder/factory can help separate concerns.\\n4. **Global presence**: Singletons provide a global access point to a service, which can lead to issues with layered access and dependency visibility.\\n5. **Stateful vs Stateless Singleton**: Stateful singletons have mutable state that requires synchronization, while stateless singletons do not.\\n6. **Distributed systems**: True singletons may be challenging in distributed systems due to the need for global registries/repositories.\\n7. **Life-cycle & life span**: Singletons are long-lived and require careful consideration when it comes to creation, initialization, and serialization.\\n8. **When to use Singleton**: The pattern should be used when every user uses the class exactly the same way, or when there is a need for global state management.\\n\\nAdditionally, the document covers the Adapter pattern, which is a design pattern that allows classes with incompatible interfaces to work together by converting the interface of one class into another.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What is the document about?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
